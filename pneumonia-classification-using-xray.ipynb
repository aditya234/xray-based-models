{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from pathlib import Path  # for path handling\nimport pydicom # to read dicom files\nimport numpy as np  \nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm # to get a nice progress bar\nimport os\n\nimport torch\nimport torchvision\nfrom torchvision import transforms\nimport torchmetrics\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import ModelCheckpoint\nfrom pytorch_lightning.loggers import TensorBoardLogger\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-28T06:56:03.072958Z","iopub.execute_input":"2022-02-28T06:56:03.073341Z","iopub.status.idle":"2022-02-28T06:56:06.529722Z","shell.execute_reply.started":"2022-02-28T06:56:03.073253Z","shell.execute_reply":"2022-02-28T06:56:06.528804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = pd.read_csv('/kaggle/input/rsna-pneumonia-detection-challenge/stage_2_train_labels.csv')\nlabels.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-02-28T06:56:06.531894Z","iopub.execute_input":"2022-02-28T06:56:06.532141Z","iopub.status.idle":"2022-02-28T06:56:06.611067Z","shell.execute_reply.started":"2022-02-28T06:56:06.532106Z","shell.execute_reply":"2022-02-28T06:56:06.610319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# to enable autocomplete in kaggle\n%config Completer.use_jedi = False","metadata":{"execution":{"iopub.status.busy":"2022-02-28T06:56:06.61243Z","iopub.execute_input":"2022-02-28T06:56:06.612682Z","iopub.status.idle":"2022-02-28T06:56:06.625313Z","shell.execute_reply.started":"2022-02-28T06:56:06.612648Z","shell.execute_reply":"2022-02-28T06:56:06.624409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = labels.drop_duplicates('patientId')","metadata":{"execution":{"iopub.status.busy":"2022-02-28T06:56:06.627603Z","iopub.execute_input":"2022-02-28T06:56:06.627897Z","iopub.status.idle":"2022-02-28T06:56:06.649736Z","shell.execute_reply.started":"2022-02-28T06:56:06.627834Z","shell.execute_reply":"2022-02-28T06:56:06.64899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ROOT_DIR = '../input/rsna-pneumonia-detection-challenge'\nROOT_PATH = Path(ROOT_DIR+'/stage_2_train_images')\nSAVE_PATH = Path(ROOT_DIR+'Processed')","metadata":{"execution":{"iopub.status.busy":"2022-02-28T06:56:06.651006Z","iopub.execute_input":"2022-02-28T06:56:06.651231Z","iopub.status.idle":"2022-02-28T06:56:06.658229Z","shell.execute_reply.started":"2022-02-28T06:56:06.651197Z","shell.execute_reply":"2022-02-28T06:56:06.657512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axis = plt.subplots(3, 3, figsize=(9,9))\n\nc = 0\nfor i in range(3):\n    for j in range(3):\n        patientId = labels.patientId.iloc[c]\n        dcmPath = ROOT_PATH/patientId\n        dcmPath = dcmPath.with_suffix('.dcm')\n        dcmFile = pydicom.read_file(dcmPath).pixel_array\n        label = labels.Target.iloc[c]\n        \n        axis[i][j].imshow(dcmFile, cmap='bone')\n        axis[i][j].set_title(label)\n        c+=1","metadata":{"execution":{"iopub.status.busy":"2022-02-28T06:56:06.659966Z","iopub.execute_input":"2022-02-28T06:56:06.660517Z","iopub.status.idle":"2022-02-28T06:56:09.118218Z","shell.execute_reply.started":"2022-02-28T06:56:06.660443Z","shell.execute_reply":"2022-02-28T06:56:09.11756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean, std = np.array([]), np.array([])\n\nto_tensor_transform = transforms.Compose([\n    transforms.ToTensor()\n])\n\nfor c, patiendId in enumerate(tqdm(labels.patientId)):\n    patientId = labels.patientId.iloc[c]\n    dcmPath = ROOT_PATH/patientId\n    dcmPath = dcmPath.with_suffix('.dcm')\n    dcmFile = pydicom.read_file(dcmPath).pixel_array / 225\n    \n    dcmArray = cv2.resize(dcmFile, (224,224)).astype(np.float16)\n    label = labels.Target.iloc[c]\n    \n    trainOrVal = \"train\" if  c< 24000 else 'val'\n    \n    path = Path(f\"{trainOrVal}/{str(label)}\")\n    path.mkdir(parents=True, exist_ok=True)\n    np.save(path/patiendId, dcmArray)\n    \n    if trainOrVal == \"train\":    \n        imageTensor = to_tensor_transform(dcmFile)\n        mean = np.append(mean, imageTensor.mean([1,2]))\n        std = np.append(std, imageTensor.std([1,2]))","metadata":{"execution":{"iopub.status.busy":"2022-02-28T06:56:09.119131Z","iopub.execute_input":"2022-02-28T06:56:09.119334Z","iopub.status.idle":"2022-02-28T07:04:33.269599Z","shell.execute_reply.started":"2022-02-28T06:56:09.119304Z","shell.execute_reply":"2022-02-28T07:04:33.268903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_image_mean = mean.mean()\ntrain_image_std = std.std()\ntrain_image_mean, train_image_std","metadata":{"execution":{"iopub.status.busy":"2022-02-28T07:04:33.27067Z","iopub.execute_input":"2022-02-28T07:04:33.271434Z","iopub.status.idle":"2022-02-28T07:04:33.278804Z","shell.execute_reply.started":"2022-02-28T07:04:33.271395Z","shell.execute_reply":"2022-02-28T07:04:33.278038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_file(path):\n    return np.load(path).astype(np.float32)\n\n\ntrain_transforms = transforms.Compose([\n                                    transforms.ToTensor(),  # Convert numpy array to tensor\n                                    transforms.Normalize(train_image_mean, train_image_std),  # Use mean and std calculated in preprocessing notebook\n                                    transforms.RandomAffine( # Data Augmentation\n                                        degrees=(-5, 5), translate=(0, 0.05), scale=(0.9, 1.1)),\n                                        transforms.RandomResizedCrop((224, 224), scale=(0.35, 1))\n\n])\n\nval_transforms = transforms.Compose([\n                                    transforms.ToTensor(),  # Convert numpy array to tensor\n                                    transforms.Normalize([train_image_mean], [train_image_std]),  # Use mean and std calculated in preprocessing notebook\n])","metadata":{"execution":{"iopub.status.busy":"2022-02-28T07:04:33.280233Z","iopub.execute_input":"2022-02-28T07:04:33.280709Z","iopub.status.idle":"2022-02-28T07:04:33.288552Z","shell.execute_reply.started":"2022-02-28T07:04:33.280671Z","shell.execute_reply":"2022-02-28T07:04:33.287886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = torchvision.datasets.DatasetFolder(\n    \"train/\",\n    loader=load_file, extensions=\"npy\", transform=train_transforms)\n\nval_dataset = torchvision.datasets.DatasetFolder(\n    \"val/\",\n    loader=load_file, extensions=\"npy\", transform=val_transforms)","metadata":{"execution":{"iopub.status.busy":"2022-02-28T07:04:33.29222Z","iopub.execute_input":"2022-02-28T07:04:33.292422Z","iopub.status.idle":"2022-02-28T07:04:33.44744Z","shell.execute_reply.started":"2022-02-28T07:04:33.292399Z","shell.execute_reply":"2022-02-28T07:04:33.446758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axis = plt.subplots(2, 2, figsize=(9, 9))\nfor i in range(2):\n    for j in range(2):\n        random_index = np.random.randint(0, 20000)\n        x_ray, label = train_dataset[random_index]\n        axis[i][j].imshow(x_ray[0], cmap=\"bone\")\n        axis[i][j].set_title(f\"Label:{label}\")","metadata":{"execution":{"iopub.status.busy":"2022-02-28T07:04:33.448618Z","iopub.execute_input":"2022-02-28T07:04:33.44887Z","iopub.status.idle":"2022-02-28T07:04:34.201641Z","shell.execute_reply.started":"2022-02-28T07:04:33.448818Z","shell.execute_reply":"2022-02-28T07:04:34.201054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 64 \nnum_workers = 4\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True)\nval_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n\nprint(f\"There are {len(train_dataset)} train images and {len(val_dataset)} val images\")","metadata":{"execution":{"iopub.status.busy":"2022-02-28T07:04:34.202802Z","iopub.execute_input":"2022-02-28T07:04:34.203196Z","iopub.status.idle":"2022-02-28T07:04:34.214371Z","shell.execute_reply.started":"2022-02-28T07:04:34.20316Z","shell.execute_reply":"2022-02-28T07:04:34.213306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.unique(train_dataset.targets, return_counts=True), np.unique(val_dataset.targets, return_counts=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-28T07:04:34.215929Z","iopub.execute_input":"2022-02-28T07:04:34.216225Z","iopub.status.idle":"2022-02-28T07:04:34.229238Z","shell.execute_reply.started":"2022-02-28T07:04:34.216189Z","shell.execute_reply":"2022-02-28T07:04:34.228275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PneumoniaModel(pl.LightningModule):\n    def __init__(self, weight=1):\n        super().__init__()\n        \n        self.model = torchvision.models.resnet18()\n        # change conv1 from 3 to 1 input channels\n        self.model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n        # change out_feature of the last fully connected layer (called fc in resnet18) from 1000 to 1\n        self.model.fc = torch.nn.Linear(in_features=512, out_features=1)\n        \n        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-4)\n        self.loss_fn = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor([weight]))\n        \n        # simple accuracy computation\n        self.train_acc = torchmetrics.Accuracy()\n        self.val_acc = torchmetrics.Accuracy()\n\n    def forward(self, data):\n        pred = self.model(data)\n        return pred\n    \n    def training_step(self, batch, batch_idx):\n        x_ray, label = batch\n        label = label.float()  # Convert label to float (just needed for loss computation)\n        pred = self(x_ray)[:,0]  # Prediction: Make sure prediction and label have same shape\n        loss = self.loss_fn(pred, label)  # Compute the loss\n        \n        # Log loss and batch accuracy\n        self.log(\"Train Loss\", loss)\n        self.log(\"Step Train Acc\", self.train_acc(torch.sigmoid(pred), label.int()))\n        return loss\n    \n    \n    def training_epoch_end(self, outs):\n        # After one epoch compute the whole train_data accuracy\n        self.log(\"Train Acc\", self.train_acc.compute())\n        \n        \n    def validation_step(self, batch, batch_idx):\n        # Same steps as in the training_step\n        x_ray, label = batch\n        label = label.float()\n        pred = self(x_ray)[:,0]  # make sure prediction and label have same shape\n\n        loss = self.loss_fn(pred, label)\n        \n        # Log validation metrics\n        self.log(\"Val Loss\", loss)\n        self.log(\"Step Val Acc\", self.val_acc(torch.sigmoid(pred), label.int()))\n        return loss\n    \n    def validation_epoch_end(self, outs):\n        self.log(\"Val Acc\", self.val_acc.compute())\n    \n    def configure_optimizers(self):\n        #Caution! You always need to return a list here (just pack your optimizer into one :))\n        return [self.optimizer]","metadata":{"execution":{"iopub.status.busy":"2022-02-28T07:04:34.23076Z","iopub.execute_input":"2022-02-28T07:04:34.231121Z","iopub.status.idle":"2022-02-28T07:04:34.245737Z","shell.execute_reply.started":"2022-02-28T07:04:34.231088Z","shell.execute_reply":"2022-02-28T07:04:34.245078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = PneumoniaModel()\n\n# Create the checkpoint callback\ncheckpoint_callback = ModelCheckpoint(\n    monitor='Val Acc',\n    save_top_k=10,\n    dirpath='weights/',\n    filename=\"model-{epoch:02d}-{val_loss:.2f}\",\n    mode='max')\n\n# Create the trainer\n# Change the gpus parameter to the number of available gpus on your system. Use 0 for CPU training\n\ngpus = 1\ntrainer = pl.Trainer(gpus=gpus, logger=TensorBoardLogger(save_dir=\"./logs\"), log_every_n_steps=1,\n                     callbacks=checkpoint_callback,\n                     max_epochs=35)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-28T07:04:34.247082Z","iopub.execute_input":"2022-02-28T07:04:34.247463Z","iopub.status.idle":"2022-02-28T07:04:34.485582Z","shell.execute_reply.started":"2022-02-28T07:04:34.247428Z","shell.execute_reply":"2022-02-28T07:04:34.484891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.fit(model, train_loader, val_loader)","metadata":{"execution":{"iopub.status.busy":"2022-02-28T07:04:34.486642Z","iopub.execute_input":"2022-02-28T07:04:34.48689Z","iopub.status.idle":"2022-02-28T07:42:42.898779Z","shell.execute_reply.started":"2022-02-28T07:04:34.486857Z","shell.execute_reply":"2022-02-28T07:42:42.897988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n# Use strict=False, otherwise we would want to match the pos_weight which is not necessary\nmodel = PneumoniaModel.load_from_checkpoint(\"./weights/model-epoch=33-val_loss=0.00.ckpt\")\nmodel.eval()\nmodel.to(device);","metadata":{"execution":{"iopub.status.busy":"2022-02-28T07:45:36.583907Z","iopub.execute_input":"2022-02-28T07:45:36.584337Z","iopub.status.idle":"2022-02-28T07:45:36.890258Z","shell.execute_reply.started":"2022-02-28T07:45:36.584303Z","shell.execute_reply":"2022-02-28T07:45:36.889491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for dirname, _, filenames in os.walk('./weights'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2022-02-28T07:44:54.553884Z","iopub.execute_input":"2022-02-28T07:44:54.554428Z","iopub.status.idle":"2022-02-28T07:44:54.560639Z","shell.execute_reply.started":"2022-02-28T07:44:54.55439Z","shell.execute_reply":"2022-02-28T07:44:54.559897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = []\nlabels = []\n\nwith torch.no_grad():\n    for data, label in tqdm(val_dataset):\n        data = data.to(device).float().unsqueeze(0)\n        pred = torch.sigmoid(model(data)[0].cpu())\n        preds.append(pred)\n        labels.append(label)\npreds = torch.tensor(preds)\nlabels = torch.tensor(labels).int()","metadata":{"execution":{"iopub.status.busy":"2022-02-28T07:45:53.943804Z","iopub.execute_input":"2022-02-28T07:45:53.944381Z","iopub.status.idle":"2022-02-28T07:46:05.868922Z","shell.execute_reply.started":"2022-02-28T07:45:53.944346Z","shell.execute_reply":"2022-02-28T07:46:05.868182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = torchmetrics.Accuracy()(preds, labels)\nprecision = torchmetrics.Precision()(preds, labels)\nrecall = torchmetrics.Recall()(preds, labels)\ncm = torchmetrics.ConfusionMatrix(num_classes=2)(preds, labels)\ncm_threshed = torchmetrics.ConfusionMatrix(num_classes=2, threshold=0.25)(preds, labels)\n\nprint(f\"Val Accuracy: {acc}\")\nprint(f\"Val Precision: {precision}\")\nprint(f\"Val Recall: {recall}\")\nprint(f\"Confusion Matrix:\\n {cm}\")\nprint(f\"Confusion Matrix 2:\\n {cm_threshed}\")","metadata":{"execution":{"iopub.status.busy":"2022-02-28T07:46:17.345739Z","iopub.execute_input":"2022-02-28T07:46:17.34601Z","iopub.status.idle":"2022-02-28T07:46:17.3752Z","shell.execute_reply.started":"2022-02-28T07:46:17.345981Z","shell.execute_reply":"2022-02-28T07:46:17.374499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axis = plt.subplots(3, 3, figsize=(9, 9))\n\nfor i in range(3):\n    for j in range(3):\n        rnd_idx = np.random.randint(0, len(preds))\n        axis[i][j].imshow(val_dataset[rnd_idx][0][0], cmap=\"bone\")\n        axis[i][j].set_title(f\"Pred:{int(preds[rnd_idx] > 0.5)}, Label:{labels[rnd_idx]}\")\n        axis[i][j].axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-02-28T07:47:13.955643Z","iopub.execute_input":"2022-02-28T07:47:13.955919Z","iopub.status.idle":"2022-02-28T07:47:14.505833Z","shell.execute_reply.started":"2022-02-28T07:47:13.955888Z","shell.execute_reply":"2022-02-28T07:47:14.505232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}